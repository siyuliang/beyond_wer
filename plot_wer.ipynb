{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e944ec-fa66-4326-b41d-3e9508418245",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using data directory: results_beam_600s\n",
      "INFO: Using training hours CSV: whisper_training_hours.csv\n",
      "INFO: Output directory: analysis_results_beam\n",
      "INFO: Language WER metrics saved to analysis_results_beam/language_wer_metrics.csv\n",
      "INFO: Collected results for 28 languages.\n",
      "INFO: Excluded 7 languages from plotting: mt, uz, sw, cs, sq, yo, da\n",
      "INFO: Scatter plot correlation: r=-0.598, p-value=0.00421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Scatter Plot Correlation ---\n",
      "Pearson correlation coefficient (r): -0.598\n",
      "P-value: 0.00421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Scatter plot 'wer_vs_hours' saved to analysis_results_beam (including SVG for text editing)\n",
      "INFO: WER vs Hours plot written to /home/siyu/analysis_results_beam\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Whisper Analysis: WER vs Training Hours\n",
    "=======================================\n",
    "\n",
    "Generates plots of word error rate (WER) against Whisper training hours\n",
    "for various languages.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import re\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from jiwer import wer\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# ────────────────────────────────────────────────────────────\n",
    "# Configuration\n",
    "# ────────────────────────────────────────────────────────────\n",
    "DATA_DIR = Path(\"results_beam_600s\")\n",
    "TRAINING_HOURS_CSV = Path(\"whisper_training_hours.csv\")\n",
    "OUTPUT_DIR = Path(\"analysis_results_beam\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "HIGH_RESOURCE = {\"de\", \"es\", \"fr\", \"pt\", \"tr\"}\n",
    "MEDIUM_RESOURCE = {\"it\", \"nl\", \"sv\", \"ca\", \"fi\", \"id\", \"vi\", \"ro\",\n",
    "                   \"no\", \"cs\", \"hu\", \"yo\"}\n",
    "LOW_RESOURCE = {\"cy\", \"lt\", \"lv\", \"az\", \"et\", \"eu\"}\n",
    "\n",
    "EXCLUDED_LANGUAGES = {\"uz\", \"mt\", \"sw\", \"sq\", \"yo\", \"da\", \"vi\", \"cs\"}\n",
    "\n",
    "COLOUR = {\"High\": \"steelblue\", \"Medium\": \"seagreen\",\n",
    "          \"Low\": \"crimson\", \"Other\": \"grey\"}\n",
    "MARKER = {\"High\": \"o\", \"Medium\": \"^\", \"Low\": \"s\", \"Other\": \"x\"}\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"figure.dpi\": 100,\n",
    "    \"savefig.dpi\": 300,\n",
    "    \"font.size\": 8,\n",
    "    \"axes.titlesize\": 10,\n",
    "    \"axes.labelsize\": 8,\n",
    "    \"xtick.labelsize\": 7,\n",
    "    \"ytick.labelsize\": 7,\n",
    "    \"legend.fontsize\": 7,\n",
    "    \"figure.titlesize\": 12\n",
    "})\n",
    "\n",
    "# ────────────────────────────────────────────────────────────\n",
    "# Utility helpers\n",
    "# ────────────────────────────────────────────────────────────\n",
    "_token_re = re.compile(r\"[^\\w\\s']|_\")\n",
    "_bracket_re = re.compile(r\"\\[.*?\\]\")\n",
    "\n",
    "\n",
    "def normalise(text: str) -> str:\n",
    "    \"\"\"Lower-case, strip punctuation & bracketed comments, normalise spaces.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = _bracket_re.sub(\"\", text.lower())\n",
    "    text = _token_re.sub(\" \", text)\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "\n",
    "def get_resource_group(code: str | None) -> str:\n",
    "    if code in HIGH_RESOURCE:\n",
    "        return \"High\"\n",
    "    if code in MEDIUM_RESOURCE:\n",
    "        return \"Medium\"\n",
    "    if code in LOW_RESOURCE:\n",
    "        return \"Low\"\n",
    "    return \"Other\"\n",
    "\n",
    "\n",
    "def load_hours(csv: Path) -> Dict[str, float]:\n",
    "    \"\"\"Return mapping Whisper_Code → training_hours (float).\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(csv)\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"Training hours CSV file not found: {csv}\")\n",
    "        return {}\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to read training hours CSV {csv}: {e}\")\n",
    "        return {}\n",
    "\n",
    "    df = df[df[\"Whisper_Training_Hours\"].notna()]\n",
    "    df = df[df[\"Whisper_Training_Hours\"] != \"Unknown\"]\n",
    "    try:\n",
    "        return (df.set_index(\"Whisper_Code\")[\"Whisper_Training_Hours\"]\n",
    "                  .astype(float)\n",
    "                  .to_dict())\n",
    "    except KeyError:\n",
    "        logging.error(f\"'Whisper_Code' or 'Whisper_Training_Hours' column not found in {csv}\")\n",
    "        return {}\n",
    "    except ValueError:\n",
    "        logging.error(f\"Could not convert 'Whisper_Training_Hours' to float in {csv}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "def safe_read_csv(path: Path, **kw) -> pd.DataFrame:\n",
    "    try:\n",
    "        return pd.read_csv(path, **kw)\n",
    "    except FileNotFoundError:\n",
    "        logging.warning(\"File not found: %s\", path.name)\n",
    "        return pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        logging.warning(\"Failed to read %s (%s)\", path.name, e)\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────────────────\n",
    "# Core analysis\n",
    "# ────────────────────────────────────────────────────────────\n",
    "def calc_wer(df: pd.DataFrame) -> float:\n",
    "    if \"step\" in df.columns:\n",
    "        df_filtered = df[df[\"step\"] == -1]\n",
    "    else:\n",
    "        logging.warning(\"'step' column not found in DataFrame. Attempting to calculate WER on all rows.\")\n",
    "        df_filtered = df\n",
    "\n",
    "    if df_filtered.empty:\n",
    "        logging.debug(\"DataFrame is empty after filtering for step == -1 or 'step' column missing.\")\n",
    "        return np.nan\n",
    "\n",
    "    if {\"ground_truth\", \"full_transcription\"}.difference(df_filtered.columns):\n",
    "        logging.warning(\"Missing 'ground_truth' or 'full_transcription' columns.\")\n",
    "        return np.nan\n",
    "\n",
    "    refs = df_filtered[\"ground_truth\"].map(normalise).tolist()\n",
    "    hyps = df_filtered[\"full_transcription\"].map(normalise).tolist()\n",
    "\n",
    "    pairs = [(r, h) for r, h in zip(refs, hyps) if isinstance(r, str) and r.strip() and isinstance(h, str) and h.strip()]\n",
    "\n",
    "    if not pairs:\n",
    "        logging.debug(\"No valid (reference, hypothesis) pairs found after normalization and filtering.\")\n",
    "        return np.nan\n",
    "\n",
    "    r_clean, h_clean = zip(*pairs)\n",
    "    return wer(list(r_clean), list(h_clean))\n",
    "\n",
    "\n",
    "def process_language(csv_path: Path, hours: Dict[str, float]) -> Dict:\n",
    "    parts = csv_path.stem.split(\"_\")\n",
    "    lang_name = (parts[1] if len(parts) >= 2 else csv_path.stem).capitalize()\n",
    "\n",
    "    df = safe_read_csv(csv_path)\n",
    "\n",
    "    code = None\n",
    "    if not df.empty and \"whisper_lang\" in df.columns:\n",
    "        unique_codes = df[\"whisper_lang\"].dropna().unique()\n",
    "        if len(unique_codes) == 1:\n",
    "            code = unique_codes[0]\n",
    "        elif len(unique_codes) > 1:\n",
    "            logging.warning(f\"Multiple whisper_lang codes found in {csv_path.name}: {unique_codes}. Using the first one: {unique_codes[0]}\")\n",
    "            code = unique_codes[0]\n",
    "        else:\n",
    "            logging.warning(f\"No valid whisper_lang codes found in {csv_path.name} after dropping NaNs.\")\n",
    "\n",
    "    num_utterances = 0\n",
    "    if not df.empty and \"step\" in df.columns:\n",
    "        num_utterances = int((df[\"step\"] == -1).sum())\n",
    "    elif not df.empty:\n",
    "        num_utterances = len(df)\n",
    "\n",
    "    out = {\n",
    "        \"language\": lang_name,\n",
    "        \"code\": code,\n",
    "        \"wer\": calc_wer(df.copy()),\n",
    "        \"training_hours\": hours.get(code, np.nan) if code else np.nan,\n",
    "        \"num_utterances\": num_utterances,\n",
    "    }\n",
    "    out[\"resource_group\"] = get_resource_group(out[\"code\"])\n",
    "    return out\n",
    "\n",
    "\n",
    "def collect_results(data_dir: Path, hours_csv: Path) -> pd.DataFrame:\n",
    "    hours = load_hours(hours_csv)\n",
    "    if not hours:\n",
    "        logging.warning(\"Training hours data could not be loaded. 'training_hours' will be NaN.\")\n",
    "\n",
    "    csvs = sorted(data_dir.glob(\"*_subtoken_beam.csv\"))\n",
    "    if not csvs:\n",
    "        logging.error(\"No CSV files matching '*_subtoken_beam.csv' found in %s\", data_dir)\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    rows = [process_language(p, hours) for p in csvs]\n",
    "    if not rows:\n",
    "        logging.error(\"No data processed from CSV files.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    try:\n",
    "        df.to_csv(OUTPUT_DIR / \"language_wer_metrics.csv\", index=False)\n",
    "        logging.info(f\"Language WER metrics saved to {OUTPUT_DIR / 'language_wer_metrics.csv'}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to save language_wer_metrics.csv: {e}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────────────────\n",
    "# Plotting helpers\n",
    "# ────────────────────────────────────────────────────────────\n",
    "def plot_scatter(df: pd.DataFrame):\n",
    "    df_filtered = df[~df[\"code\"].isin(EXCLUDED_LANGUAGES)]\n",
    "    if len(df) != len(df_filtered):\n",
    "        logging.info(f\"Excluded {len(df) - len(df_filtered)} languages from plotting: {', '.join(EXCLUDED_LANGUAGES)}\")\n",
    "\n",
    "    df_plot = df_filtered.dropna(subset=[\"wer\", \"training_hours\"])\n",
    "    if df_plot.empty:\n",
    "        logging.warning(\"No data to plot (scatter) after dropping NaNs in 'wer' or 'training_hours'.\")\n",
    "        return\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(4.5, 3.5))\n",
    "\n",
    "    for grp_name, gdf in df_plot.groupby(\"resource_group\"):\n",
    "        marker = MARKER.get(grp_name, \"x\")\n",
    "        color = COLOUR.get(grp_name, \"grey\")\n",
    "        ax.scatter(gdf[\"training_hours\"], gdf[\"wer\"],\n",
    "                   s=40, alpha=.7, marker=marker,\n",
    "                   label=f\"{grp_name}-resource\", color=color)\n",
    "        for _, r in gdf.iterrows():\n",
    "            ax.annotate(r.language, (r.training_hours, r.wer),\n",
    "                        xytext=(3, 1), textcoords=\"offset points\", fontsize=6)\n",
    "\n",
    "    if len(df_plot) >= 2:\n",
    "        valid_hours_idx = np.isfinite(np.log10(df_plot[\"training_hours\"]))\n",
    "        valid_hours = df_plot[\"training_hours\"][valid_hours_idx]\n",
    "        valid_wer = df_plot[\"wer\"][valid_hours_idx]\n",
    "\n",
    "        finite_wer_idx = np.isfinite(valid_wer)\n",
    "        valid_hours = valid_hours[finite_wer_idx]\n",
    "        valid_wer = valid_wer[finite_wer_idx]\n",
    "\n",
    "        if len(valid_hours) >= 2:\n",
    "            xs = np.log10(valid_hours)\n",
    "            z = np.polyfit(xs, valid_wer, 1)\n",
    "            p_poly = np.poly1d(z)\n",
    "\n",
    "            correlation_coefficient, p_value_calc = pearsonr(xs, valid_wer)\n",
    "\n",
    "            print(f\"--- Scatter Plot Correlation ---\")\n",
    "            print(f\"Pearson correlation coefficient (r): {correlation_coefficient:.3f}\")\n",
    "            print(f\"P-value: {p_value_calc:.3g}\")\n",
    "            logging.info(f\"Scatter plot correlation: r={correlation_coefficient:.3f}, p-value={p_value_calc:.3g}\")\n",
    "\n",
    "            trend_label = f\"Trend (r={correlation_coefficient:.2f})\"\n",
    "\n",
    "            min_log_x = xs.min()\n",
    "            max_log_x = xs.max()\n",
    "            if min_log_x < max_log_x:\n",
    "                x_line = np.logspace(min_log_x, max_log_x, 100)\n",
    "                ax.plot(x_line, p_poly(np.log10(x_line)), \"k--\", linewidth=1,\n",
    "                        label=trend_label)\n",
    "            else:\n",
    "                logging.warning(\"Could not plot trend line due to insufficient range in training hours after log.\")\n",
    "        else:\n",
    "            logging.warning(\"Not enough valid data points to calculate trend line, r, and p-value.\")\n",
    "\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_xlabel(\"Whisper training hours (log scale)\")\n",
    "    ax.set_ylabel(\"WER\")\n",
    "    ax.set_ylim(0, min(2, df_plot.wer.max()*1.1) if not df_plot.empty and pd.notna(df_plot.wer.max()) else 2)\n",
    "    ax.legend()\n",
    "    ax.grid(True, linestyle='--', alpha=0.5)\n",
    "    fig.tight_layout(pad=0.5)\n",
    "\n",
    "    fig.savefig(OUTPUT_DIR / \"wer_vs_hours.svg\", format=\"svg\")\n",
    "    fig.savefig(OUTPUT_DIR / \"wer_vs_hours.png\")\n",
    "    fig.savefig(OUTPUT_DIR / \"wer_vs_hours.pdf\")\n",
    "\n",
    "    logging.info(f\"Scatter plot 'wer_vs_hours' saved to {OUTPUT_DIR} (including SVG)\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def plot_ranked_bar(df: pd.DataFrame):\n",
    "    df_filtered = df[~df[\"code\"].isin(EXCLUDED_LANGUAGES)]\n",
    "    df_plot = df_filtered.dropna(subset=[\"wer\", \"language\"]).sort_values(\"wer\")\n",
    "    if df_plot.empty:\n",
    "        logging.warning(\"No data to plot (ranked bar) after dropping NaNs in 'wer' or 'language'.\")\n",
    "        return\n",
    "\n",
    "    fig_height = max(2.5, 0.18 * len(df_plot))\n",
    "    fig_width = 4.0\n",
    "    fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "\n",
    "    colors = [COLOUR.get(get_resource_group(c), \"grey\") for c in df_plot.code]\n",
    "    bars = ax.barh(df_plot.language, df_plot.wer, color=colors, alpha=.8)\n",
    "\n",
    "    for bar, val in zip(bars, df_plot.wer):\n",
    "        if pd.notna(val):\n",
    "            ax.text(val + .005, bar.get_y() + bar.get_height()/2,\n",
    "                    f\"{val:.3f}\", va=\"center\", fontsize=6)\n",
    "\n",
    "    ax.set_xlabel(\"Word error rate\")\n",
    "    ax.set_xlim(0, min(2, df_plot.wer.max()*1.1) if not df_plot.empty and pd.notna(df_plot.wer.max()) else 2)\n",
    "    ax.grid(axis=\"x\", ls=\"--\", alpha=.3)\n",
    "    ax.tick_params(axis='y', labelsize=7)\n",
    "    fig.tight_layout(pad=0.5)\n",
    "    try:\n",
    "        fig.savefig(OUTPUT_DIR / \"languages_ranked_by_wer.png\")\n",
    "        fig.savefig(OUTPUT_DIR / \"languages_ranked_by_wer.pdf\")\n",
    "        logging.info(f\"Ranked bar plot 'languages_ranked_by_wer' saved to {OUTPUT_DIR}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to save ranked bar plot: {e}\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def plot_box(df: pd.DataFrame):\n",
    "    df_filtered = df[~df[\"code\"].isin(EXCLUDED_LANGUAGES)]\n",
    "    df_plot = df_filtered.dropna(subset=[\"wer\", \"resource_group\"])\n",
    "    if df_plot.empty:\n",
    "        logging.warning(\"No data to plot (box plot) after dropping NaNs in 'wer' or 'resource_group'.\")\n",
    "        return\n",
    "\n",
    "    groups = [\"High\", \"Medium\", \"Low\", \"Other\"]\n",
    "    data, labels, colours_for_plot = [], [], []\n",
    "\n",
    "    for g in groups:\n",
    "        vals = df_plot[df_plot.resource_group == g].wer.dropna()\n",
    "        if not vals.empty:\n",
    "            data.append(vals)\n",
    "            labels.append(f\"{g} (n={len(vals)})\")\n",
    "            colours_for_plot.append(COLOUR.get(g, \"grey\"))\n",
    "\n",
    "    if not data:\n",
    "        logging.warning(\"No data available for any resource group for box plot.\")\n",
    "        return\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(4, 3))\n",
    "    bp = ax.boxplot(data, patch_artist=True, labels=labels)\n",
    "\n",
    "    for patch, c in zip(bp[\"boxes\"], colours_for_plot):\n",
    "        patch.set_facecolor(c)\n",
    "        patch.set_alpha(.6)\n",
    "\n",
    "    for i, vals in enumerate(data):\n",
    "        ax.scatter(np.random.normal(i + 1, .03, len(vals)), vals,\n",
    "                   s=15, alpha=.7, color=\"black\")\n",
    "\n",
    "    ax.set_ylabel(\"Word error rate\")\n",
    "    ax.set_ylim(0, min(2, df_plot.wer.max()*1.1) if not df_plot.empty and pd.notna(df_plot.wer.max()) else 2)\n",
    "    fig.tight_layout(pad=0.5)\n",
    "    try:\n",
    "        fig.savefig(OUTPUT_DIR / \"wer_by_resource_group.png\")\n",
    "        fig.savefig(OUTPUT_DIR / \"wer_by_resource_group.pdf\")\n",
    "        logging.info(f\"Box plot 'wer_by_resource_group' saved to {OUTPUT_DIR}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to save box plot: {e}\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────────────────\n",
    "# CLI entry\n",
    "# ────────────────────────────────────────────────────────────\n",
    "def parse_args(custom_argv: Optional[List[str]]) -> argparse.Namespace:\n",
    "    p = argparse.ArgumentParser(description=\"Plot Whisper WER vs training hours\")\n",
    "    p.add_argument(\"--data_dir\", type=Path, default=DATA_DIR,\n",
    "                   help=\"Directory with *_subtoken_beam.csv files\")\n",
    "    p.add_argument(\"--hours_csv\", type=Path, default=TRAINING_HOURS_CSV,\n",
    "                   help=\"CSV mapping Whisper_Code → training hours\")\n",
    "    p.add_argument(\"-q\", \"--quiet\", action=\"store_true\", help=\"Suppress info logs\")\n",
    "    return p.parse_args(custom_argv if custom_argv is not None else sys.argv[1:])\n",
    "\n",
    "\n",
    "def main(custom_argv: Optional[List[str]] = None):\n",
    "    args_to_parse = custom_argv\n",
    "    if custom_argv is None and any('ipykernel_launcher.py' in arg for arg in sys.argv):\n",
    "        args_to_parse = []\n",
    "    elif custom_argv is None:\n",
    "        args_to_parse = sys.argv[1:]\n",
    "\n",
    "    args = parse_args(args_to_parse)\n",
    "\n",
    "    logging.basicConfig(level=logging.WARNING if args.quiet else logging.INFO,\n",
    "                        format=\"%(levelname)s: %(message)s\")\n",
    "\n",
    "    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    logging.info(f\"Using data directory: {args.data_dir}\")\n",
    "    logging.info(f\"Using training hours CSV: {args.hours_csv}\")\n",
    "    logging.info(f\"Output directory: {OUTPUT_DIR}\")\n",
    "\n",
    "    df = collect_results(args.data_dir, args.hours_csv)\n",
    "\n",
    "    if df.empty:\n",
    "        logging.error(\"No usable results – exiting.\")\n",
    "        return\n",
    "\n",
    "    logging.info(\"Collected results for %d languages.\", len(df[df['language'].notna()]))\n",
    "\n",
    "    plot_scatter(df)\n",
    "\n",
    "    logging.info(f\"WER vs Hours plot written to {OUTPUT_DIR.resolve()}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (whisper_env)",
   "language": "python",
   "name": "whisper_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
